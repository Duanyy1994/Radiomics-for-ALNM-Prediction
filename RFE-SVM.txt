## -------------------- rfeSVM)-----------------------
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import os
dataDir = r'data_path' 
train_filename = '/train_filename' 
test_filename = '/test_filename'
os.chdir(dataDir)
# The first column is ID; Second is label; cc means the last clinical factor, cc+1 to end is radiomics features
def rfesvm():
    ## ------------------- 0. data reading -------------------------
    train_data = pd.read_csv(dataDir + train_filename + '.csv')
    print('Train_data', train_data.head())

    cc = 2  # the location of last clinical factor
    x_train = train_data[train_data.columns[cc:]]  
    y_train = train_data[train_data.columns[1]]
    print(x_train)

    ## ------ standard------------------
    stdsc = StandardScaler()
    x_train = stdsc.fit_transform(x_train)  
    x_train = pd.DataFrame(x_train)


    ## --------------------Test----------------------
    test_data = pd.read_csv(dataDir + test_filename + '.csv')
    x_test = test_data[test_data.columns[cc:]]  # 
    y_test = test_data[test_data.columns[1]]
    x_test = stdsc.transform(x_test)  # 
    x_test = pd.DataFrame(x_test)

    # ----------- label 加-------------
    print('Postive rate', sum(y_train) / len(y_train))
    print('Negative rate', sum(y_test) / len(y_test))
    ratio = len(y_train) / sum(y_train) - 1
    print('ratio', ratio)

####################################################################################################
    # ## -----------RFE-SVM  --------------------
    from sklearn.svm import SVC
    from sklearn.feature_selection import RFECV
    from sklearn.model_selection import StratifiedKFold
    from sklearn.model_selection import GridSearchCV 
    model_svm = SVC(kernel='linear', gamma='auto', probability=True, class_weight={0: 1, 1: ratio}, random_state=60)  # ,
    rfecv = RFECV(estimator=model_svm, step=1, cv=StratifiedKFold(5), scoring='roc_auc')
    rfecv.fit(x_train, y_train)
    print(rfecv.grid_scores_)
    score = pd.DataFrame(rfecv.grid_scores_)
    score.to_csv(dataDir + "/rfecv.grid_scores_.csv", encoding='gbk', index=False)

    print("\n\nOptimal number of features : %d" % rfecv.n_features_)
    print('\nBest features(rank=1):')
    for f in range(x_train.shape[1]):
        if rfecv.ranking_[f] == 1:
           print(train_data.columns[f + cc])


    plt.close()
    plt.figure()
    plt.rcParams['font.sans-serif'] = ['SimHei'] 
    plt.rcParams['axes.unicode_minus'] = False
    plt.ylim(0.5, 1)
    plt.xlabel("Number of features selected")
    plt.ylabel("Cross validation score (average of auc)")
    plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)
    figure_name = 'rfeSVM.tiff'
    plt.savefig(dataDir + str(figure_name))
    # plt.show()

    ## ------------------ Save feature --------------------------
    train_feature = train_data[train_data.columns[cc:]].loc[:, rfecv.ranking_ == 1]
    test_feature = test_data[test_data.columns[cc:]].loc[:, rfecv.ranking_ == 1]

    train_data = pd.concat([train_data['p_ID'], train_data['label'], train_feature], axis=1)
    test_data = pd.concat([test_data['p_ID'], test_data['label'], test_feature], axis=1)

    x_train = train_data[train_data.columns[2:]]  
    y_train = train_data[train_data.columns[1]]
    x_test = test_data[test_data.columns[2:]]  
    y_test = test_data[test_data.columns[1]]

    ## ------ Standard------------------
    stdsc = StandardScaler()
    x_train = stdsc.fit_transform(x_train)  #
    x_train = pd.DataFrame(x_train)
    x_test = stdsc.transform(x_test)  
    x_test = pd.DataFrame(x_test)
######################################################################################
    from sklearn.model_selection import cross_val_score
    from sklearn.svm import SVC
    best_score = 0
    for kernel in ['linear', 'rbf']:
        for gamma in [0.001, 0.01, 0.1, 1, 5, 10, 50]:
            for C in [0.001, 0.01, 0.1, 1, 5, 10, 50]:  # 0.001, 0.01, 0.1, 1, 5, 10, 50
                svm_rfe_cv = SVC(kernel=kernel, gamma=gamma, C=C, probability=True, random_state=60,
                                 class_weight={0: 1, 1: ratio}, shrinking=True).fit(x_train, y_train)
                # score = np.mean(cross_val_score(svm_rfe_cv, x_train, y_train, n_jobs=-1, cv=5, scoring='roc_auc'))  # 在训练集和验证集上进行交叉验证
                # score = np.mean(cross_val_score(svm_rfe_cv, x_test, y_test, n_jobs=-1, cv=5, scoring='roc_auc'))

                y_train_predict = svm_rfe_cv.predict(x_train)
                y_test_predict = svm_rfe_cv.predict(x_test)
                from sklearn import metrics
                train_score = metrics.roc_auc_score(y_train, y_train_predict)
                test_score = metrics.roc_auc_score(y_test, y_test_predict)
                score = min(train_score, test_score)  # compute min cross-validation roc_auc

                # print('Running', kernel, gamma, C, round(train_score, 3), round(test_score, 3))
                if score > best_score:
                    best_score = score
                    best_parameters = {'kernel': kernel, 'C': C, 'gamma': gamma}
                    best_model_svm = svm_rfe_cv

    print('\nBestScore', best_score)
    print('BestParameters', best_parameters)


    import joblib
    joblib.dump(best_model_svm, "svm_rfe_cv.pkl")

    # # ----------------------------Model performance --------------------------------
    import joblib
    svm_rfe_cv = joblib.load("svm_rfe_cv.pkl")
    y_train_predict = svm_rfe_cv.predict(x_train)
    y_train_proba = svm_rfe_cv.predict_proba(x_train)
    y_train_proba = y_train_proba[:, 1]

    from sklearn import metrics
    print('Train: \n', metrics.confusion_matrix(y_train, y_train_predict))
    print('Train: AUC_Score', metrics.roc_auc_score(y_train, y_train_proba))
    print('Train: accuracy ', metrics.accuracy_score(y_train, y_train_predict))
    print('Train: precision', metrics.precision_score(y_train, y_train_predict))
    print('Train: recall   ', metrics.recall_score(y_train, y_train_predict))
    print('Train: F1_score ', metrics.f1_score(y_train, y_train_predict))
    print('\n')

    # # -----------------Model performance----------------------
    import joblib
    svm_rfe_cv = joblib.load("svm_rfe_cv.pkl")
    y_test_predict = svm_rfe_cv.predict(x_test)
    y_test_proba = svm_rfe_cv.predict_proba(x_test)
    y_test_proba = y_test_proba[:, 1]

    from sklearn import metrics
    print('Test：\n', metrics.confusion_matrix(y_test, y_test_predict))
    print('Test：AUC_Score', metrics.roc_auc_score(y_test, y_test_proba))
    print('Test：accuracy ', metrics.accuracy_score(y_test, y_test_predict))
    print('Test：precision', metrics.precision_score(y_test, y_test_predict))
    print('Test：recall   ', metrics.recall_score(y_test, y_test_predict))
    print('Test：F1_score ', metrics.f1_score(y_test, y_test_predict))

    ## -----------------------------Output-------------------------------
    y_train_proba = svm_rfe_cv.predict_proba(x_train)
    y_test_proba = svm_rfe_cv.predict_proba(x_test)

    df = pd.DataFrame()
    df.loc[:, 'p_ID'] = train_data[train_data.columns[0]]
    df.loc[:, 'label'] = y_train
    df.loc[:, 'predict'] = y_train_proba[:, 1]
    df = pd.concat([df, train_data[train_data.columns[2:]]], axis=1)
    df.to_csv(dataDir + "/SVM_train_predict_train.csv", encoding='gbk', index=False)

    df = pd.DataFrame()
    df.loc[:, 'p_ID'] = test_data[test_data.columns[0]]
    df.loc[:, 'label'] = y_test
    df.loc[:, 'predict'] = y_test_proba[:, 1]
    df = pd.concat([df, test_data[test_data.columns[2:]]], axis=1)
    df.to_csv(dataDir + "/SVM_test_predict.csv", encoding='gbk', index=False)
    # print("Optimal number of features : %d" % rfecv.n_features_)
    print('Finished')
    print('\n')


if __name__ == "__main__":
    rfesvm()